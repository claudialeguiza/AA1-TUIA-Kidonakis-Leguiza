{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUJEmoUBxUUv8aSELCdvUw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudialeguiza/AA1-TUIA-Kidonakis-Leguiza/blob/navegador/generar_modelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cLXc7T2zEqU4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.pipeline import Pipeline\n",
        "import keras\n",
        "from keras.models import Sequential, save_model, load_model\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos = pd.read_csv('/content/weatherAUS.csv', delimiter = \",\")"
      ],
      "metadata": {
        "id": "-30WTKMoFk2h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = datos[datos.Location\\\n",
        "                      .isin(( 'Sydney','SydneyAirport','Melbourne', 'MelbourneAirport',\\\n",
        "                             'Canberra','Adelaide', 'MountGambier','Cobar', 'Dartmoor' ))]"
      ],
      "metadata": {
        "id": "D8UxDqY7GAQf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocesamiento(data):\n",
        "    data.info()\n",
        "    data.isna().sum()\n",
        "\n",
        "    # Definir columnas con valores nulos\n",
        "    columnas_con_nulos = ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine',\n",
        "                          'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm','Humidity9am',\n",
        "                          'Humidity3pm', 'Pressure9am','Pressure3pm', 'Cloud9am',\n",
        "                          'Cloud3pm', 'Temp9am', 'Temp3pm', 'RainfallTomorrow']\n",
        "\n",
        "    # Rellenar valores faltantes en 'RainToday' y 'RainTomorrow'\n",
        "    data['RainToday'] = data.groupby('Date')['RainToday'].transform(lambda x: x.fillna(x.mode().iloc[0]))\n",
        "    data['RainTomorrow'] = data.groupby('Date')['RainTomorrow'].transform(lambda x: x.fillna(x.mode().iloc[0]))\n",
        "\n",
        "    # Rellenar valores faltantes en direcciones del viento\n",
        "    data['WindGustDir'] = data.groupby('Date')['WindGustDir'].transform(lambda x: x.fillna(x.mode().iloc[0]) if not x.isna().all() else x)\n",
        "    data['WindDir9am'] = data.groupby('Date')['WindDir9am'].transform(lambda x: x.fillna(x.mode().iloc[0]) if not x.isna().all() else x)\n",
        "    data['WindDir3pm'] = data.groupby('Date')['WindDir3pm'].transform(lambda x: x.fillna(x.mode().iloc[0]) if not x.isna().all() else x)\n",
        "\n",
        "    # Rellenar valores faltantes con la media por día para las columnas especificadas\n",
        "    media_por_dia = data.groupby('Date')[columnas_con_nulos].transform('mean')\n",
        "    data[columnas_con_nulos] = data[columnas_con_nulos].fillna(media_por_dia)\n",
        "\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "Vm6gEs76HBKk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crear_columna_season(data):\n",
        "   data['season'] = data['Date'].apply(asignar_estacion)\n",
        "   return data"
      ],
      "metadata": {
        "id": "BJx1V3tHHViG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def asignar_estacion(fecha):\n",
        "    mes = fecha.month\n",
        "    if mes in [12, 1, 2]:  # Verano: Diciembre, Enero, Febrero\n",
        "        return 'Summer'\n",
        "    elif mes in [3, 4, 5]:  # Otoño: Marzo, Abril, Mayo\n",
        "        return 'Autumn'\n",
        "    elif mes in [6, 7, 8]:  # Invierno: Junio, Julio, Agosto\n",
        "        return 'Winter'\n",
        "    else:  # Primavera: Septiembre, Octubre, Noviembre\n",
        "        return 'Spring'"
      ],
      "metadata": {
        "id": "25SCfZasHepN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def codificar_variables(data):\n",
        "\n",
        "  data1 = data.copy()\n",
        "\n",
        "  for var in [\"SW\", \"S\", 'SSW', 'W', 'SSE', 'E', 'SE', 'NE', 'NNE', 'WSW', 'WNW',\n",
        "            'NW', 'N', 'ESE', 'ENE']:\n",
        "    # Crear columnas para WindGustDir\n",
        "    data1[f'WindGustDir_{var}'] = 0\n",
        "    data1.loc[data['WindGustDir'] == var, f'WindGustDir_{var}'] = 1\n",
        "\n",
        "    # Crear columnas para WindGust9am\n",
        "    data1[f'WindDir9am_{var}'] = 0\n",
        "    data1.loc[data['WindDir9am'] == var, f'WindDir9am_{var}'] = 1\n",
        "\n",
        "    # Crear columnas para WindGust3pm\n",
        "    data1[f'WindDir3pm_{var}'] = 0\n",
        "    data1.loc[data['WindDir3pm'] == var, f'WindDir3pm_{var}'] = 1\n",
        "\n",
        "    # Generamos dummys\n",
        "    # Codificar la variable 'RainToday'\n",
        "  data1 = pd.get_dummies(data1, columns=['RainToday'],drop_first=True)\n",
        "\n",
        "    # Codificar la variable 'RainTomorrow'\n",
        "  data1 = pd.get_dummies(data1, columns=['RainTomorrow'],drop_first=True)\n",
        "\n",
        "    # Codificar la variable 'season'\n",
        "  data1 = pd.get_dummies(data1, columns=['season'],drop_first=True)\n",
        "\n",
        "    # Codificar la variable 'Location'\n",
        "  data1 = pd.get_dummies(data1, columns=['Location'], drop_first=True)\n",
        "  data1 = data1.drop(columns= ['WindGustDir', 'WindDir9am', 'WindDir3pm'])\n",
        "  data1 = data1.drop(columns = ['Unnamed: 0'])\n",
        "\n",
        "  return data1"
      ],
      "metadata": {
        "id": "JngxP-xIHjFl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def estandarizar_df(data):\n",
        "  scaler = RobustScaler()\n",
        "  data_scaled = scaler.fit_transform(data)\n",
        "  return data_scaled"
      ],
      "metadata": {
        "id": "py6hmsCWWbUi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def truncar_dividir_df(data):\n",
        "  data = data.sort_values([\"Date\"])\n",
        "  fecha_especifica = '2009-01-01'\n",
        "  data_filtrada = data[data['Date'] >= fecha_especifica]\n",
        "\n",
        "  data_filtrada.reset_index(drop = True, inplace = True)#Resetea el indice y no  crea uno  nuevo\n",
        "  data_train  = data_filtrada.iloc[:21658]\n",
        "  data_test = data_filtrada.iloc[21658:]\n",
        "\n",
        "  return data_train"
      ],
      "metadata": {
        "id": "t4iH0DupLSY8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def estandarizar_regresion(data):\n",
        "\n",
        "  # Separar variables inependientes y dependintes\n",
        "   X_regresion = data.drop(columns=['RainfallTomorrow', 'Date'])\n",
        "   X_scaled = estandarizar_df(X_regresion)\n",
        "   y_regresion = data['RainfallTomorrow']\n",
        "   y_scaled = estandarizar_df(y_regresion)\n",
        "   return X_scaled, y_scaled"
      ],
      "metadata": {
        "id": "zJk2EMejqT5l"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def estandarizar_balancear_clasificacion(data):\n",
        "\n",
        "   X_clasificacion = data.drop(columns=['RainTomorrow_Yes', \"RainfallTomorrow\",\"Date\"])\n",
        "   X_scaled1 = estandarizar_df(X_clasificacion)\n",
        "   y_clasificacion = data['RainTomorrow_Yes']\n",
        "   y_scaled1 = estandarizar_df(y_clasificacion)\n",
        "\n",
        "   smote  = SMOTE(random_state =42)\n",
        "   X_smote_scaled, y_smote_scaled = smote.fit_resample(X_scaled1,y_scaled1)\n",
        "\n",
        "   return X_smote_scaled, y_smote_scaled\n",
        ""
      ],
      "metadata": {
        "id": "Uto6RXcgcruv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_prepara_datos = Pipeline([\n",
        "    ('imputar',preprocesamiento(df), crear_columna_season(df)),\n",
        "    ('truncar', truncar_dividir_df(df)),\n",
        "    ('codificar', codificar_variables(df)),\n",
        "    ('estandarizar',estandarizar_regresion(df))\n",
        "     ])\n",
        "\n",
        "x_train_scaled, y_train_scaled = pipeline_prepara_datos(df)\n",
        "\n",
        "\n",
        "\n",
        "pipeline_regresion.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "joblib.dump(pipe_regresionregresion, 'models/regresion_pipeline.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        },
        "id": "QXESzQ93GB1A",
        "outputId": "89657869-f13a-43b9-d37e-ac3674ba47ef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 28233 entries, 6047 to 102519\n",
            "Data columns (total 26 columns):\n",
            " #   Column            Non-Null Count  Dtype         \n",
            "---  ------            --------------  -----         \n",
            " 0   Unnamed: 0        28233 non-null  int64         \n",
            " 1   Date              28233 non-null  datetime64[ns]\n",
            " 2   Location          28233 non-null  object        \n",
            " 3   MinTemp           28233 non-null  float64       \n",
            " 4   MaxTemp           28233 non-null  float64       \n",
            " 5   Rainfall          28233 non-null  float64       \n",
            " 6   Evaporation       28233 non-null  float64       \n",
            " 7   Sunshine          28233 non-null  float64       \n",
            " 8   WindGustDir       28229 non-null  object        \n",
            " 9   WindGustSpeed     28231 non-null  float64       \n",
            " 10  WindDir9am        28231 non-null  object        \n",
            " 11  WindDir3pm        28233 non-null  object        \n",
            " 12  WindSpeed9am      28233 non-null  float64       \n",
            " 13  WindSpeed3pm      28233 non-null  float64       \n",
            " 14  Humidity9am       28233 non-null  float64       \n",
            " 15  Humidity3pm       28233 non-null  float64       \n",
            " 16  Pressure9am       28233 non-null  float64       \n",
            " 17  Pressure3pm       28233 non-null  float64       \n",
            " 18  Cloud9am          28233 non-null  float64       \n",
            " 19  Cloud3pm          28233 non-null  float64       \n",
            " 20  Temp9am           28233 non-null  float64       \n",
            " 21  Temp3pm           28233 non-null  float64       \n",
            " 22  RainToday         28233 non-null  object        \n",
            " 23  RainTomorrow      28233 non-null  object        \n",
            " 24  RainfallTomorrow  28233 non-null  float64       \n",
            " 25  season            28233 non-null  object        \n",
            "dtypes: datetime64[ns](1), float64(17), int64(1), object(7)\n",
            "memory usage: 5.8+ MB\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'Cobar'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-7b039f7b828b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'truncar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncar_dividir_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'codificar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodificar_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m'estandarizar'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mestandarizar_regresion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m      ])\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-83004cdf108c>\u001b[0m in \u001b[0;36mestandarizar_regresion\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# Separar variables inependientes y dependintes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0mX_regresion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RainfallTomorrow'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m    \u001b[0mX_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestandarizar_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_regresion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m    \u001b[0my_regresion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RainfallTomorrow'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m    \u001b[0my_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestandarizar_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_regresion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-4b68ba4bd269>\u001b[0m in \u001b[0;36mestandarizar_df\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mestandarizar_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobustScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mdata_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata_scaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0;31m# at fit, convert sparse matrices to csc for optimized computation of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m         \u001b[0;31m# the quantiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m   1517\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         if (\n\u001b[1;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Cobar'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_clasificacion = Pipeline([\n",
        "    ('imputer', preprocesamiento(df), crear_columna_season(df), codificar_variables(df)),\n",
        "    ('scaler', RobustScaler()),\n",
        "    ('model', classification_model_best_params)\n",
        "])\n",
        "\n",
        "pipe_clasificacion.fit(X_smote_train, y_smote_train)\n",
        "\n",
        "joblib.dump(pipe_clasificacion, 'models/clasificacion_pipeline.joblib')"
      ],
      "metadata": {
        "id": "emoswcDTGW0G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}